{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n# 簡介 #\n\n本專案將使用分布式運算訓練DL(有使用TPU)，對104種花卉圖片進行分類。","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\nimport math, re, os\nimport pandas as pd\nimport numpy as np\nimport random\nimport plotly.express as px\n\nimport tensorflow as tf\nprint(\"Tensorflow version \" + tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T06:13:10.727099Z","iopub.execute_input":"2022-01-01T06:13:10.727462Z","iopub.status.idle":"2022-01-01T06:13:18.405657Z","shell.execute_reply.started":"2022-01-01T06:13:10.727352Z","shell.execute_reply":"2022-01-01T06:13:18.404540Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# 定義分布運算策略 \nTPU= 8 GPU","metadata":{}},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu) \n    tf.tpu.experimental.initialize_tpu_system(tpu) \n    strategy = tf.distribute.experimental.TPUStrategy(tpu) \nelse:\n    strategy = tf.distribute.get_strategy() \n\nprint(\"運算單元數: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T06:13:18.407857Z","iopub.execute_input":"2022-01-01T06:13:18.408183Z","iopub.status.idle":"2022-01-01T06:13:24.518991Z","shell.execute_reply.started":"2022-01-01T06:13:18.408144Z","shell.execute_reply":"2022-01-01T06:13:24.518083Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# 參數設定","metadata":{}},{"cell_type":"code","source":"IMAGE_SIZE = [512, 512]\nBATCH_SIZE = 16 #此為每個分布單元之batchsize\nEPOCHS = 20\nAUTO = tf.data.experimental.AUTOTUNE\n\nMODEL_NAME = ['EfficientNetB7']\nCLASSES = ['pink primrose',    'hard-leaved pocket orchid', 'canterbury bells', 'sweet pea',     'wild geranium',     'tiger lily',           'moon orchid',              'bird of paradise', 'monkshood',        'globe thistle',         # 10個\n           'snapdragon',       \"colt's foot\",               'king protea',      'spear thistle', 'yellow iris',       'globe-flower',         'purple coneflower',        'peruvian lily',    'balloon flower',   'giant white arum lily', \n           'fire lily',        'pincushion flower',         'fritillary',       'red ginger',    'grape hyacinth',    'corn poppy',           'prince of wales feathers', 'stemless gentian', 'artichoke',        'sweet william',         \n           'carnation',        'garden phlox',              'love in the mist', 'cosmos',        'alpine sea holly',  'ruby-lipped cattleya', 'cape flower',              'great masterwort', 'siam tulip',       'lenten rose',           \n           'barberton daisy',  'daffodil',                  'sword lily',       'poinsettia',    'bolero deep blue',  'wallflower',           'marigold',                 'buttercup',        'daisy',            'common dandelion',      \n           'petunia',          'wild pansy',                'primula',          'sunflower',     'lilac hibiscus',    'bishop of llandaff',   'gaura',                    'geranium',         'orange dahlia',    'pink-yellow dahlia',    \n           'cautleya spicata', 'japanese anemone',          'black-eyed susan', 'silverbush',    'californian poppy', 'osteospermum',         'spring crocus',            'iris',             'windflower',       'tree poppy',            \n           'gazania',          'azalea',                    'water lily',       'rose',          'thorn apple',       'morning glory',        'passion flower',           'lotus',            'toad lily',        'anthurium',             \n           'frangipani',       'clematis',                  'hibiscus',         'columbine',     'desert-rose',       'tree mallow',          'magnolia',                 'cyclamen ',        'watercress',       'canna lily',            \n           'hippeastrum ',     'bee balm',                  'pink quill',       'foxglove',      'bougainvillea',     'camellia',             'mallow',                   'mexican petunia',  'bromelia',         'blanket flower',        \n           'trumpet creeper',  'blackberry lily',           'common tulip',     'wild rose']     ","metadata":{"execution":{"iopub.status.busy":"2022-01-01T06:13:24.520548Z","iopub.execute_input":"2022-01-01T06:13:24.521033Z","iopub.status.idle":"2022-01-01T06:13:24.532983Z","shell.execute_reply.started":"2022-01-01T06:13:24.520991Z","shell.execute_reply":"2022-01-01T06:13:24.532199Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# 從GCS載入數據\n\n為了使用TPU，則必須把資料上傳至Google雲端數據桶，方便TPU即時擷取資料不延遲。","metadata":{}},{"cell_type":"code","source":"from kaggle_datasets import KaggleDatasets\n\ngcs_ds_path = KaggleDatasets().get_gcs_path('tpu-getting-started')\ngcs_path = gcs_ds_path + f'/tfrecords-jpeg-{IMAGE_SIZE[0]}x{IMAGE_SIZE[1]}'\n \n\ntraining_filenames = tf.io.gfile.glob(gcs_path + '/train/*.tfrec')\nvalidation_filenames = tf.io.gfile.glob(gcs_path + '/val/*.tfrec')\ntest_filenames = tf.io.gfile.glob(gcs_path + '/test/*.tfrec')                          ","metadata":{"execution":{"iopub.status.busy":"2022-01-01T06:13:24.535315Z","iopub.execute_input":"2022-01-01T06:13:24.535585Z","iopub.status.idle":"2022-01-01T06:13:25.199150Z","shell.execute_reply.started":"2022-01-01T06:13:24.535559Z","shell.execute_reply":"2022-01-01T06:13:25.198389Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## 匯入額外資料集","metadata":{}},{"cell_type":"code","source":"gcs_ds_path_EXT = KaggleDatasets().get_gcs_path('tf-flower-photo-tfrec')\n\ngcs_path_SELECT_EXT = {\n    192: '/tfrecords-jpeg-192x192',\n    224: '/tfrecords-jpeg-224x224',\n    331: '/tfrecords-jpeg-331x331',\n    512: '/tfrecords-jpeg-512x512'\n}\ngcs_path_EXT = gcs_path_SELECT_EXT[IMAGE_SIZE[0]]\n\nimageNet_files = tf.io.gfile.glob(gcs_ds_path_EXT + '/imagenet' + gcs_path_EXT + '/*.tfrec')\ninatureList_files = tf.io.gfile.glob(gcs_ds_path_EXT + '/inaturalist' + gcs_path_EXT + '/*.tfrec')\nopenImage_files = tf.io.gfile.glob(gcs_ds_path_EXT + '/openimage' + gcs_path_EXT + '/*.tfrec')\noxford_files = tf.io.gfile.glob(gcs_ds_path_EXT + '/oxford_102' + gcs_path_EXT + '/*.tfrec')\ntensorflow_files = tf.io.gfile.glob(gcs_ds_path_EXT + '/tf_flowers' + gcs_path_EXT + '/*.tfrec')\n\nadditional_training_filenames = imageNet_files + inatureList_files + openImage_files + oxford_files + tensorflow_files  \n\ntraining_filenames = training_filenames + additional_training_filenames","metadata":{"execution":{"iopub.status.busy":"2022-01-01T06:13:25.200165Z","iopub.execute_input":"2022-01-01T06:13:25.200367Z","iopub.status.idle":"2022-01-01T06:13:25.965837Z","shell.execute_reply.started":"2022-01-01T06:13:25.200344Z","shell.execute_reply":"2022-01-01T06:13:25.964849Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# 數據讀取function\n","metadata":{}},{"cell_type":"code","source":"def decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0  # 標準化\n    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n    return image\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"class\": tf.io.FixedLenFeature([], tf.int64),\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    label = tf.cast(example['class'], tf.int32)\n    return image, label\n\ndef read_unlabeled_tfrecord(example):\n    UNLABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), \n        \"id\": tf.io.FixedLenFeature([], tf.string), \n    }\n    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    idnum = example['id']\n    return image, idnum\n\ndef load_dataset(filenames, labeled=True, ordered=False):\n\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # 增加運算速度\n\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n    dataset = dataset.with_options(ignore_order) \n    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n    # returns (image, label) 或是 (image, id)\n    return dataset","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-01T06:13:25.966986Z","iopub.execute_input":"2022-01-01T06:13:25.967228Z","iopub.status.idle":"2022-01-01T06:13:25.979671Z","shell.execute_reply.started":"2022-01-01T06:13:25.967199Z","shell.execute_reply":"2022-01-01T06:13:25.978613Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# 數據增強","metadata":{}},{"cell_type":"code","source":"SEED = 2020  #數據增強引入隨機性\n\n#隨機遮蔽\ndef random_blockout(img, sl=0.1, sh=0.2, rl=0.4):\n    p=random.random()\n    if p>=0.25:\n        w, h, c = IMAGE_SIZE[0], IMAGE_SIZE[1], 3\n        origin_area = tf.cast(h*w, tf.float32)\n\n        e_size_l = tf.cast(tf.round(tf.sqrt(origin_area * sl * rl)), tf.int32)\n        e_size_h = tf.cast(tf.round(tf.sqrt(origin_area * sh / rl)), tf.int32)\n\n        e_height_h = tf.minimum(e_size_h, h)\n        e_width_h = tf.minimum(e_size_h, w)\n\n        erase_height = tf.random.uniform(shape=[], minval=e_size_l, maxval=e_height_h, dtype=tf.int32)\n        erase_width = tf.random.uniform(shape=[], minval=e_size_l, maxval=e_width_h, dtype=tf.int32)\n\n        erase_area = tf.zeros(shape=[erase_height, erase_width, c])\n        erase_area = tf.cast(erase_area, tf.uint8)\n\n        pad_h = h - erase_height\n        pad_top = tf.random.uniform(shape=[], minval=0, maxval=pad_h, dtype=tf.int32)\n        pad_bottom = pad_h - pad_top\n\n        pad_w = w - erase_width\n        pad_left = tf.random.uniform(shape=[], minval=0, maxval=pad_w, dtype=tf.int32)\n        pad_right = pad_w - pad_left\n\n        erase_mask = tf.pad([erase_area], [[0,0],[pad_top, pad_bottom], [pad_left, pad_right], [0,0]], constant_values=1)\n        erase_mask = tf.squeeze(erase_mask, axis=0)\n        erased_img = tf.multiply(tf.cast(img,tf.float32), tf.cast(erase_mask, tf.float32))\n\n        return tf.cast(erased_img, img.dtype)\n    else:\n        return tf.cast(img, img.dtype)\n\n    \ndef data_augment_v2(image, label):\n    \n    flag = random.randint(1,3)\n    coef_1 = random.randint(60, 80) * 0.01\n    coef_2 = random.randint(60, 80) * 0.01\n    \n    if flag == 1:\n        image = tf.image.random_flip_left_right(image, seed=SEED)\n    elif flag == 2:\n        image = tf.image.random_flip_up_down(image, seed=SEED)\n    else:\n        image = tf.image.random_crop(image, [int(IMAGE_SIZE[0]*coef_1), int(IMAGE_SIZE[0]*coef_2), 3],seed=SEED)\n        \n    image = random_blockout(image)\n    \n    return image, label ","metadata":{"execution":{"iopub.status.busy":"2022-01-01T06:13:25.981230Z","iopub.execute_input":"2022-01-01T06:13:25.981603Z","iopub.status.idle":"2022-01-01T06:13:26.000359Z","shell.execute_reply.started":"2022-01-01T06:13:25.981561Z","shell.execute_reply":"2022-01-01T06:13:25.999735Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# 數據增強v3","metadata":{}},{"cell_type":"code","source":"import tensorflow_addons as tfa\n\ndef data_augment_v3(image, label):\n    seed = 100\n    \n    image = tf.image.resize(image, [720, 720])\n    image = tf.image.random_crop(image, [512, 512, 3], seed = seed)\n\n    image = tf.image.random_brightness(image, 0.6, seed = seed)\n    \n    image = tf.image.random_saturation(image, 3, 5, seed = seed)\n        \n    image = tf.image.random_contrast(image, 0.3, 0.5, seed = seed)\n    \n    image = tfa.image.mean_filter2d(image, filter_shape = 10)\n    \n    image = tf.image.random_flip_left_right(image, seed = seed)\n    image = tf.image.random_flip_up_down(image, seed = seed)\n    \n    return image, label","metadata":{"execution":{"iopub.status.busy":"2022-01-01T06:13:26.001629Z","iopub.execute_input":"2022-01-01T06:13:26.002057Z","iopub.status.idle":"2022-01-01T06:13:26.113322Z","shell.execute_reply.started":"2022-01-01T06:13:26.002029Z","shell.execute_reply":"2022-01-01T06:13:26.112605Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# 建立數據Pipeline","metadata":{}},{"cell_type":"code","source":"def data_augment(image, label):\n    image = tf.image.random_flip_left_right(image)\n    return image, label   \n\ndef get_training_dataset():\n    dataset = load_dataset(training_filenames, labeled=True)\n    dataset = dataset.map(data_augment, num_parallel_calls=AUTO) # 引用數據增強\n    dataset = dataset.repeat()\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(AUTO) \n    return dataset\n\ndef get_validation_dataset(ordered=False):\n    dataset = load_dataset(validation_filenames, labeled=True, ordered=ordered)\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\ndef get_test_dataset(ordered=False):\n    dataset = load_dataset(test_filenames, labeled=False, ordered=ordered)\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\ndef count_data_items(filenames):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n\nnum_training_images = count_data_items(training_filenames)\nnum_validation_images = count_data_items(validation_filenames)\nnum_test_images = count_data_items(test_filenames)\nprint('{}筆train, {}筆val, {}筆未標註的test'.format(num_training_images, num_validation_images, num_test_images))\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-01T06:13:26.114609Z","iopub.execute_input":"2022-01-01T06:13:26.114913Z","iopub.status.idle":"2022-01-01T06:13:26.129772Z","shell.execute_reply.started":"2022-01-01T06:13:26.114877Z","shell.execute_reply":"2022-01-01T06:13:26.128748Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"strategy.num_replicas_in_sync\nbatch_size = BATCH_SIZE * strategy.num_replicas_in_sync # batch_size = BATCH_SIZE乘以分布數量\n\nds_train = get_training_dataset()\nds_valid = get_validation_dataset()\nds_test = get_test_dataset()\n\nprint(\"Train:\", ds_train)\nprint (\"Val:\", ds_valid)\nprint(\"Test:\", ds_test)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T06:13:26.133863Z","iopub.execute_input":"2022-01-01T06:13:26.134568Z","iopub.status.idle":"2022-01-01T06:13:26.470981Z","shell.execute_reply.started":"2022-01-01T06:13:26.134526Z","shell.execute_reply":"2022-01-01T06:13:26.470107Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#preview\nnp.set_printoptions(threshold=15, linewidth=80)\n\nprint(\"Training data shapes:\")\nfor image, label in ds_train.take(3):\n    print(image.numpy().shape, label.numpy().shape) #See Note 3.1 above 😀\nprint(\"Training data label examples:\", label.numpy())","metadata":{"execution":{"iopub.status.busy":"2022-01-01T06:13:26.472374Z","iopub.execute_input":"2022-01-01T06:13:26.472712Z","iopub.status.idle":"2022-01-01T06:13:32.814653Z","shell.execute_reply.started":"2022-01-01T06:13:26.472675Z","shell.execute_reply":"2022-01-01T06:13:32.813367Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(\"Test data shapes:\")\nfor image, idnum in ds_test.take(3):\n    print(image.numpy().shape, idnum.numpy().shape) \nprint(\"Test data IDs:\", idnum.numpy().astype('U'))","metadata":{"execution":{"iopub.status.busy":"2022-01-01T06:13:32.815926Z","iopub.execute_input":"2022-01-01T06:13:32.816651Z","iopub.status.idle":"2022-01-01T06:13:35.913272Z","shell.execute_reply.started":"2022-01-01T06:13:32.816615Z","shell.execute_reply":"2022-01-01T06:13:35.912288Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"# 計算類別權重\nfrom collections import Counter\nimport gc\ngc.enable()\n\ndef get_training_dataset_raw():\n    dataset = load_dataset(training_filenames, labeled = True, ordered = False)\n    return dataset\n\nraw_training_dataset = get_training_dataset_raw()\n\nlabel_counter = Counter()\nfor images, labels in raw_training_dataset:\n    label_counter.update([labels.numpy()])\n\ndel raw_training_dataset    \n\nTARGET_NUM_PER_CLASS = 122 \n\ndef get_weight_for_class(class_id):\n    counting = label_counter[class_id]\n    weight = TARGET_NUM_PER_CLASS / counting\n    return weight\n\nweight_per_class = {class_id: get_weight_for_class(class_id) for class_id in range(104)}","metadata":{"execution":{"iopub.status.busy":"2022-01-01T06:13:35.914651Z","iopub.execute_input":"2022-01-01T06:13:35.914901Z","iopub.status.idle":"2022-01-01T06:15:34.729212Z","shell.execute_reply.started":"2022-01-01T06:13:35.914874Z","shell.execute_reply":"2022-01-01T06:15:34.728332Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"data = pd.DataFrame.from_dict(weight_per_class, orient='index', columns=['class_weight'])\nplt.figure(figsize=(30, 9))\n\n#barplot color based on value\nbplot = sns.barplot(x=data.index, y='class_weight', data=data, palette= cm.Blues(data['class_weight']*0.15));\nfor p in bplot.patches:\n    bplot.annotate(format(p.get_height(), '.1f'), \n                    (p.get_x() + p.get_width() / 2., p.get_height()), \n                    ha = 'center', va = 'center', \n                    xytext = (0, 9), \n                    textcoords = 'offset points')\nplt.xlabel(\"Class\", size=14)\nplt.ylabel(\"Class weight (inverse of %)\", size=14)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T06:15:34.730409Z","iopub.execute_input":"2022-01-01T06:15:34.730646Z","iopub.status.idle":"2022-01-01T06:15:36.990124Z","shell.execute_reply.started":"2022-01-01T06:15:34.730618Z","shell.execute_reply":"2022-01-01T06:15:36.989211Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n\ndef batch_to_numpy_images_and_labels(data):\n    images, labels = data\n    numpy_images = images.numpy()\n    numpy_labels = labels.numpy()\n    if numpy_labels.dtype == object: # binary string in this case,these are image ID strings\n        numpy_labels = [None for _ in enumerate(numpy_images)]\n        # If no labels, only image IDs, return None for labels (this is the case for test data)\n    return numpy_images, numpy_labels\n\ndef title_from_label_and_target(label, correct_label):\n    if correct_label is None:\n        return CLASSES[label], True\n    correct = (label == correct_label)\n    return \"{} [{}{}{}]\".format(CLASSES[label], \n                                'OK' if correct else 'NO', \n                                u\"\\u2192\" if not correct else '',\n                                CLASSES[correct_label] if not correct else ''), correct\n\ndef display_one_flower(image, title, subplot, red=False, titlesize=16):\n    plt.subplot(*subplot)\n    plt.axis('off')\n    plt.imshow(image)\n    if len(title) > 0:\n        plt.title(title, fontsize=int(titlesize) if not red else int(titlesize/1.2), color='red' if red else 'black', fontdict={'verticalalignment':'center'}, pad=int(titlesize/1.5))\n    return (subplot[0], subplot[1], subplot[2]+1)\n    \ndef display_batch_of_images(databatch, predictions=None, display_mismatches_only=False):\n    \"\"\"This will work with:\n    display_batch_of_images(images)\n    display_batch_of_images(images, predictions)\n    display_batch_of_images((images, labels))\n    display_batch_of_images((images, labels), predictions)\n    \"\"\"\n    # data\n    images, labels = batch_to_numpy_images_and_labels(databatch)\n    if labels is None:\n        labels = [None for _ in enumerate(images)]\n        \n    # auto-squaring: this will drop data that does not fit into square or square-ish rectangle\n    rows = int(math.sqrt(len(images)))\n    cols = len(images)//rows\n        \n    # size and spacing\n    FIGSIZE = 13.0\n    SPACING = 0.1\n    subplot=(rows,cols,1)\n    if rows < cols:\n        plt.figure(figsize=(FIGSIZE,FIGSIZE/cols*rows))\n    else:\n        plt.figure(figsize=(FIGSIZE/rows*cols,FIGSIZE))\n    \n    # display\n    for i, (image, label) in enumerate(zip(images[:rows*cols], labels[:rows*cols])):\n        title = '' if label is None else CLASSES[label]\n        correct = True\n        if predictions is not None:\n            title, correct = title_from_label_and_target(predictions[i], label)\n        dynamic_titlesize = FIGSIZE*SPACING/max(rows,cols)*40+3 # magic formula tested to work from 1x1 to 10x10 images\n        if display_mismatches_only:\n            if predictions[i] != label:\n                subplot = display_one_flower(image, title, subplot, not correct, titlesize=dynamic_titlesize)\n        else:        \n            subplot = display_one_flower(image, title, subplot, not correct, titlesize=dynamic_titlesize)\n    \n    #layout\n    plt.tight_layout()\n    if label is None and predictions is None:\n        plt.subplots_adjust(wspace=0, hspace=0)\n    else:\n        plt.subplots_adjust(wspace=SPACING, hspace=SPACING)\n    plt.show()\n\n\ndef display_training_curves(training, validation, title, subplot):\n    if subplot%10==1: # set up the subplots on the first call\n        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n        plt.tight_layout()\n    ax = plt.subplot(subplot)\n    ax.set_facecolor('#F8F8F8')\n    ax.plot(training)\n    ax.plot(validation)\n    ax.set_title('model '+ title)\n    ax.set_ylabel(title)\n    #ax.set_ylim(0.28,1.05)\n    ax.set_xlabel('epoch')\n    ax.legend(['train', 'valid.'])\n\ndef display_training_curves_v2(training, validation, learning_rate_list, title, subplot):\n    if subplot%10==1: # set up the subplots on the first call\n        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n        plt.tight_layout()\n    ax = plt.subplot(subplot)\n    ax.set_facecolor('#F8F8F8')\n    ax.plot(training)\n    ax.plot(validation)\n    ax.set_title('model '+ title)\n    ax.set_ylabel(title, color='b')\n    #ax.set_ylim(0.28,1.05)\n    ax.set_xlabel('epoch')\n    ax.legend(['train', 'valid.', 'learning rate'])        \n    \n    ax2 = ax.twinx()\n    ax2.plot(learning_rate_list, 'g-')\n    ax2.set_ylabel('learning rate', color='g')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-01T06:15:36.991863Z","iopub.execute_input":"2022-01-01T06:15:36.992654Z","iopub.status.idle":"2022-01-01T06:15:37.019572Z","shell.execute_reply.started":"2022-01-01T06:15:36.992611Z","shell.execute_reply":"2022-01-01T06:15:37.018519Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"ds_iter = iter(ds_train.unbatch().batch(20))","metadata":{"execution":{"iopub.status.busy":"2022-01-01T06:15:37.020828Z","iopub.execute_input":"2022-01-01T06:15:37.021399Z","iopub.status.idle":"2022-01-01T06:15:37.065669Z","shell.execute_reply.started":"2022-01-01T06:15:37.021351Z","shell.execute_reply":"2022-01-01T06:15:37.064658Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"one_batch = next(ds_iter)\ndisplay_batch_of_images(one_batch)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T06:15:37.066715Z","iopub.execute_input":"2022-01-01T06:15:37.066927Z","iopub.status.idle":"2022-01-01T06:15:41.894946Z","shell.execute_reply.started":"2022-01-01T06:15:37.066903Z","shell.execute_reply":"2022-01-01T06:15:41.893084Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## preview數據增強v1","metadata":{}},{"cell_type":"code","source":"row = 2\ncol = 3\nsize = 10\n\nall_elements = get_training_dataset().unbatch()\none_element = tf.data.Dataset.from_tensors(next(iter(all_elements)))\naugmented_element = one_element.repeat().map(data_augment).batch(row * col)\n\nfor (img, label) in augmented_element:\n    plt.figure(figsize = (size, int(size * row / col)))\n    for j in range(row * col):\n        plt.subplot(row, col, j + 1)\n        plt.axis('off')\n        plt.imshow(img[j, ])\n    plt.show()\n    break","metadata":{"execution":{"iopub.status.busy":"2022-01-01T06:15:41.896341Z","iopub.execute_input":"2022-01-01T06:15:41.896616Z","iopub.status.idle":"2022-01-01T06:15:43.940437Z","shell.execute_reply.started":"2022-01-01T06:15:41.896588Z","shell.execute_reply":"2022-01-01T06:15:43.939464Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## 數據增強v2","metadata":{}},{"cell_type":"code","source":"augmented_element = one_element.repeat().map(data_augment_v2).batch(row * col)\n\nfor (img, label) in augmented_element:\n    plt.figure(figsize = (size, int(size * row / col)))\n    for j in range(row * col):\n        plt.subplot(row, col, j + 1)\n        plt.axis('off')\n        plt.imshow(img[j, ])\n    plt.show()\n    break","metadata":{"execution":{"iopub.status.busy":"2022-01-01T06:15:43.942045Z","iopub.execute_input":"2022-01-01T06:15:43.942290Z","iopub.status.idle":"2022-01-01T06:15:45.785923Z","shell.execute_reply.started":"2022-01-01T06:15:43.942263Z","shell.execute_reply":"2022-01-01T06:15:45.785283Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## 數據增強v3","metadata":{}},{"cell_type":"code","source":"augmented_element = one_element.repeat().map(data_augment_v3).batch(row * col)\n\nfor (img, label) in augmented_element:\n    plt.figure(figsize = (size, int(size * row / col)))\n    for j in range(row * col):\n        plt.subplot(row, col, j + 1)\n        plt.axis('off')\n        plt.imshow(img[j, ])\n    plt.show()\n    break","metadata":{"execution":{"iopub.status.busy":"2022-01-01T06:15:45.786966Z","iopub.execute_input":"2022-01-01T06:15:45.787703Z","iopub.status.idle":"2022-01-01T06:15:50.656809Z","shell.execute_reply.started":"2022-01-01T06:15:45.787668Z","shell.execute_reply":"2022-01-01T06:15:50.655881Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# 建模","metadata":{}},{"cell_type":"markdown","source":"## 先定義模型架構","metadata":{}},{"cell_type":"code","source":"print('pre-train list:\\n', ', '.join(tf.keras.applications.__dir__()))","metadata":{"execution":{"iopub.status.busy":"2022-01-01T06:15:50.658258Z","iopub.execute_input":"2022-01-01T06:15:50.658639Z","iopub.status.idle":"2022-01-01T06:15:50.664310Z","shell.execute_reply.started":"2022-01-01T06:15:50.658598Z","shell.execute_reply":"2022-01-01T06:15:50.663500Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"use_efficientnet = True \nif use_efficientnet:\n    !pip install -q efficientnet\n    from efficientnet.tfkeras import EfficientNetB7","metadata":{"execution":{"iopub.status.busy":"2022-01-01T06:15:50.665745Z","iopub.execute_input":"2022-01-01T06:15:50.666026Z","iopub.status.idle":"2022-01-01T06:16:00.391937Z","shell.execute_reply.started":"2022-01-01T06:15:50.665991Z","shell.execute_reply":"2022-01-01T06:16:00.391017Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"#string as code\n# model_command = f'tf.keras.applications.{MODEL_NAME[0]}'\n# pretrained_model = eval(model_command)\n\nwith strategy.scope():\n    #pretrained_model = tf.keras.applications.DenseNet201\n    #pretrained_model = tf.keras.applications.NASNetMobile\n    #pretrained_model = tf.keras.applications.ResNet101V2\n    #pretrained_model = tf.keras.applications.MobileNetV2\n    #pretrained_model = EfficientNetB7\n\n    pretrained_model = EfficientNetB7(include_top=False, weights='imagenet', input_shape=[*IMAGE_SIZE, 3])\n    pretrained_model.trainable = True\n\n    model = tf.keras.Sequential([\n        pretrained_model,\n        tf.keras.layers.GlobalAveragePooling2D(), \n        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n        ],\n        name= MODEL_NAME[0]\n    )","metadata":{"execution":{"iopub.status.busy":"2022-01-01T06:16:00.393404Z","iopub.execute_input":"2022-01-01T06:16:00.393673Z","iopub.status.idle":"2022-01-01T06:16:42.813723Z","shell.execute_reply.started":"2022-01-01T06:16:00.393631Z","shell.execute_reply":"2022-01-01T06:16:42.812870Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    optimizer='nadam',\n    loss = 'sparse_categorical_crossentropy',\n    metrics=['sparse_categorical_accuracy'],\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T06:16:42.815595Z","iopub.execute_input":"2022-01-01T06:16:42.815919Z","iopub.status.idle":"2022-01-01T06:16:42.881923Z","shell.execute_reply.started":"2022-01-01T06:16:42.815878Z","shell.execute_reply":"2022-01-01T06:16:42.880980Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-01T06:16:42.883094Z","iopub.execute_input":"2022-01-01T06:16:42.883346Z","iopub.status.idle":"2022-01-01T06:16:42.948184Z","shell.execute_reply.started":"2022-01-01T06:16:42.883317Z","shell.execute_reply":"2022-01-01T06:16:42.947556Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T06:16:42.949297Z","iopub.execute_input":"2022-01-01T06:16:42.949670Z","iopub.status.idle":"2022-01-01T06:16:43.959396Z","shell.execute_reply.started":"2022-01-01T06:16:42.949641Z","shell.execute_reply":"2022-01-01T06:16:43.958251Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"## 定義callback","metadata":{}},{"cell_type":"code","source":"checkpoint_filepath = f\"Flowers-Classification-{model.name}.h5\"\n\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=True,\n    monitor='val_loss',\n    mode='min',\n    save_best_only=True\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T06:16:43.961172Z","iopub.execute_input":"2022-01-01T06:16:43.961971Z","iopub.status.idle":"2022-01-01T06:16:43.967176Z","shell.execute_reply.started":"2022-01-01T06:16:43.961928Z","shell.execute_reply":"2022-01-01T06:16:43.966412Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T06:16:43.973859Z","iopub.execute_input":"2022-01-01T06:16:43.974129Z","iopub.status.idle":"2022-01-01T06:16:43.981874Z","shell.execute_reply.started":"2022-01-01T06:16:43.974094Z","shell.execute_reply":"2022-01-01T06:16:43.981076Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def exponential_lr(epoch, start_lr = 0.00001, min_lr = 0.00001, max_lr = 0.00005 * strategy.num_replicas_in_sync,\n                    rampup_epochs = 5, sustain_epochs = 0,\n                    exp_decay = 0.75): \n\n    def lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay):\n        if epoch < rampup_epochs:\n            lr = ((max_lr - start_lr) / rampup_epochs * epoch + start_lr)\n        elif epoch < rampup_epochs + sustain_epochs:\n            lr = max_lr\n        else:\n            lr = ((max_lr - min_lr) * exp_decay**(epoch - rampup_epochs - sustain_epochs) + min_lr)\n        return lr\n    \n    return lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay)\n\nlr_callback = tf.keras.callbacks.LearningRateScheduler(exponential_lr, verbose=True)\n\n\nrng = [i for i in range(EPOCHS)]\ny = [exponential_lr(x) for x in rng]\nplt.plot(rng, y)\nprint(\"Learning rate curve: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))","metadata":{"execution":{"iopub.status.busy":"2022-01-01T06:16:43.982993Z","iopub.execute_input":"2022-01-01T06:16:43.983259Z","iopub.status.idle":"2022-01-01T06:16:44.230915Z","shell.execute_reply.started":"2022-01-01T06:16:43.983234Z","shell.execute_reply":"2022-01-01T06:16:44.230243Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"# 訓練","metadata":{}},{"cell_type":"markdown","source":"## Fit Model","metadata":{}},{"cell_type":"code","source":"history = model.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=EPOCHS,\n    steps_per_epoch=num_training_images / batch_size,\n    callbacks=[lr_callback, checkpoint], \n    class_weight = weight_per_class\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T06:16:44.231961Z","iopub.execute_input":"2022-01-01T06:16:44.232778Z","iopub.status.idle":"2022-01-01T09:02:54.409178Z","shell.execute_reply.started":"2022-01-01T06:16:44.232743Z","shell.execute_reply":"2022-01-01T09:02:54.408509Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"## Show result","metadata":{}},{"cell_type":"code","source":"def display_training_curves(training, validation, lr, title, subplot):\n    if subplot%10==1: # set up the subplots on the first call\n        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n        plt.tight_layout()\n    ax = plt.subplot(subplot)\n    ax.set_facecolor('#F8F8F8')\n    ax.plot(training)\n    ax.plot(validation)\n    ax.set_title('model '+ title)\n    ax.set_ylabel(title)\n    #ax.set_ylim(0.28,1.05)\n    ax.set_xlabel('epoch')\n    ax.legend(['train', 'valid.'])","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:02:54.410354Z","iopub.execute_input":"2022-01-01T09:02:54.410660Z","iopub.status.idle":"2022-01-01T09:02:54.418479Z","shell.execute_reply.started":"2022-01-01T09:02:54.410628Z","shell.execute_reply":"2022-01-01T09:02:54.417527Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"display_training_curves( \n    history.history['loss'],\n    history.history['val_loss'],\n    history.history['lr'],\n    'loss',\n    211,\n)\n\ndisplay_training_curves(\n    history.history['sparse_categorical_accuracy'],\n    history.history['val_sparse_categorical_accuracy'],\n    history.history['lr'],\n    'accuracy',\n    212,\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:02:54.420012Z","iopub.execute_input":"2022-01-01T09:02:54.423761Z","iopub.status.idle":"2022-01-01T09:02:55.124202Z","shell.execute_reply.started":"2022-01-01T09:02:54.423715Z","shell.execute_reply":"2022-01-01T09:02:55.123512Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"zoom_after = 15\ndisplay_training_curves(\n    history.history['loss'][zoom_after:],\n    history.history['val_loss'][zoom_after:],\n    history.history['lr'],\n    'loss',\n    211,\n)\n\ndisplay_training_curves(\n    history.history['sparse_categorical_accuracy'][zoom_after:],\n    history.history['val_sparse_categorical_accuracy'][zoom_after:],\n    history.history['lr'],\n    'accuracy',\n    212,\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:02:55.125362Z","iopub.execute_input":"2022-01-01T09:02:55.125680Z","iopub.status.idle":"2022-01-01T09:02:55.932297Z","shell.execute_reply.started":"2022-01-01T09:02:55.125647Z","shell.execute_reply":"2022-01-01T09:02:55.931412Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights(checkpoint_filepath)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:02:55.933498Z","iopub.execute_input":"2022-01-01T09:02:55.934212Z","iopub.status.idle":"2022-01-01T09:03:05.645810Z","shell.execute_reply.started":"2022-01-01T09:02:55.934172Z","shell.execute_reply":"2022-01-01T09:03:05.644905Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:03:05.647398Z","iopub.execute_input":"2022-01-01T09:03:05.647670Z","iopub.status.idle":"2022-01-01T09:03:05.713117Z","shell.execute_reply.started":"2022-01-01T09:03:05.647641Z","shell.execute_reply":"2022-01-01T09:03:05.712058Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"#convert to tf-lite model\n'''\nprint(checkpoint_filepath)\ntflite_model_name = checkpoint_filepath.replace('.h5', '.tflite')\ntflite_model_name\n'''\n\n'''\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\ntflite_model = converter.convert()\n\n# Save the model\nwith open(tflite_model_name, 'wb') as f:\n    f.write(tflite_model)\n    \nprint('TFLiteConversion completed successfully \\U0001F680')  \n'''","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:03:05.714658Z","iopub.execute_input":"2022-01-01T09:03:05.714891Z","iopub.status.idle":"2022-01-01T09:03:05.722668Z","shell.execute_reply.started":"2022-01-01T09:03:05.714864Z","shell.execute_reply":"2022-01-01T09:03:05.721678Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"## ensemble","metadata":{}},{"cell_type":"code","source":"if len(MODEL_NAME)>1:\n    using_ensemble_models = True\nelse:\n    using_ensemble_models = False","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:03:05.723848Z","iopub.execute_input":"2022-01-01T09:03:05.724183Z","iopub.status.idle":"2022-01-01T09:03:05.735590Z","shell.execute_reply.started":"2022-01-01T09:03:05.724142Z","shell.execute_reply":"2022-01-01T09:03:05.734317Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"def get_pretrained_model(model_name, image_dataset_weights, trainable=True):\n    pretrained_model= model_name(\n        include_top=False ,\n        weights=image_dataset_weights,\n        input_shape=[*IMAGE_SIZE, 3]\n    )\n\n    pretrained_model.trainable = trainable\n    \n    model = tf.keras.Sequential([\n        pretrained_model, \n        tf.keras.layers.GlobalAveragePooling2D(), \n        tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n    ])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:03:05.736854Z","iopub.execute_input":"2022-01-01T09:03:05.737118Z","iopub.status.idle":"2022-01-01T09:03:05.748301Z","shell.execute_reply.started":"2022-01-01T09:03:05.737090Z","shell.execute_reply":"2022-01-01T09:03:05.747598Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"if using_ensemble_models:\n    with strategy.scope():\n        model_EB7 = get_pretrained_model(EfficientNetB7, 'noisy-student', trainable=True)\n\n    model_EB7.load_weights(f'../input/models/Flowers-Classification-{model.name}.h5')    ","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:03:05.749443Z","iopub.execute_input":"2022-01-01T09:03:05.749766Z","iopub.status.idle":"2022-01-01T09:03:05.762771Z","shell.execute_reply.started":"2022-01-01T09:03:05.749724Z","shell.execute_reply":"2022-01-01T09:03:05.761949Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"if using_ensemble_models:\n    model_EB7.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:03:05.764060Z","iopub.execute_input":"2022-01-01T09:03:05.764294Z","iopub.status.idle":"2022-01-01T09:03:05.777502Z","shell.execute_reply.started":"2022-01-01T09:03:05.764267Z","shell.execute_reply":"2022-01-01T09:03:05.776256Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"if using_ensemble_models:\n    with strategy.scope():\n        model_D201 = get_pretrained_model(tf.keras.applications.DenseNet201, 'imagenet', trainable=True)\n\n    model_D201.load_weights('../input/models/Flowers-Classification-DenseNet201.h5')  ","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:03:05.779030Z","iopub.execute_input":"2022-01-01T09:03:05.779305Z","iopub.status.idle":"2022-01-01T09:03:05.790727Z","shell.execute_reply.started":"2022-01-01T09:03:05.779275Z","shell.execute_reply":"2022-01-01T09:03:05.789483Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"if using_ensemble_models:\n    model_D201.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:03:05.792046Z","iopub.execute_input":"2022-01-01T09:03:05.792335Z","iopub.status.idle":"2022-01-01T09:03:05.805307Z","shell.execute_reply.started":"2022-01-01T09:03:05.792290Z","shell.execute_reply":"2022-01-01T09:03:05.804015Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"## Ensemble both models","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:03:05.806789Z","iopub.execute_input":"2022-01-01T09:03:05.807274Z","iopub.status.idle":"2022-01-01T09:03:06.009170Z","shell.execute_reply.started":"2022-01-01T09:03:05.807226Z","shell.execute_reply":"2022-01-01T09:03:06.008166Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"if using_ensemble_models:\n    cmdataset = get_validation_dataset(ordered=True) # since we are splitting the dataset and iterating separately on images and labels, order matters.\n    images_ds = cmdataset.map(lambda image, label: image)\n    labels_ds = cmdataset.map(lambda image, label: label).unbatch()\n    cm_correct_labels = next(iter(labels_ds.batch(num_validation_images))).numpy() # get everything as one batch\n\n    m1 = model_EB7.predict(images_ds)\n    m2 = model_D201.predict(images_ds)\n\n    scores = []\n    for alpha in np.linspace(0,1,100):\n        cm_probabilities = alpha*m1+(1-alpha)*m2\n        cm_predictions = np.argmax(cm_probabilities, axis=-1)\n        scores.append(f1_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='macro'))\n\n    print(\"Correct   labels: \", cm_correct_labels.shape, cm_correct_labels)\n    print(\"Predicted labels: \", cm_predictions.shape, cm_predictions)\n    plt.plot(scores)\n\n    best_alpha = np.argmax(scores)/100\n    cm_probabilities = best_alpha*m1+(1-best_alpha)*m2\n    cm_predictions = np.argmax(cm_probabilities, axis=-1)\n\n    #best_alpha = 0.35","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:03:06.010506Z","iopub.execute_input":"2022-01-01T09:03:06.010776Z","iopub.status.idle":"2022-01-01T09:03:06.021654Z","shell.execute_reply.started":"2022-01-01T09:03:06.010747Z","shell.execute_reply":"2022-01-01T09:03:06.020468Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"if using_ensemble_models:\n    print(best_alpha, max(scores))","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:03:06.023305Z","iopub.execute_input":"2022-01-01T09:03:06.023633Z","iopub.status.idle":"2022-01-01T09:03:06.035592Z","shell.execute_reply.started":"2022-01-01T09:03:06.023557Z","shell.execute_reply":"2022-01-01T09:03:06.034452Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"if using_ensemble_models:\n    test_ds = get_test_dataset(ordered=True)\n    #best_alpha = 0.35\n\n    print('Computing predictions...')\n    test_images_ds = test_ds.map(lambda image, idnum: image)\n    probabilities1 = model_EB7.predict(test_images_ds)\n    probabilities2 = model_D201.predict(test_images_ds)\n\n    probabilities = best_alpha * probabilities1 + (1 - best_alpha) * probabilities2\n\n    predictions = np.argmax(probabilities, axis=-1)\n    print(predictions)\n\n    print('Generating submission.csv file...')\n    # Get image ids from test set and convert to unicode\n    test_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\n    test_ids = next(iter(test_ids_ds.batch(num_test_images))).numpy().astype('U')\n\n    # Write the submission file\n    np.savetxt(\n        'submission.csv',\n        np.rec.fromarrays([test_ids, predictions]),\n        fmt=['%s', '%d'],\n        delimiter=',',\n        header='id,label',\n        comments='',\n    )\n\n    # Look at the first few predictions\n    !head submission.csv","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:03:06.037317Z","iopub.execute_input":"2022-01-01T09:03:06.037645Z","iopub.status.idle":"2022-01-01T09:03:06.052122Z","shell.execute_reply.started":"2022-01-01T09:03:06.037611Z","shell.execute_reply":"2022-01-01T09:03:06.050902Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"# 評估模型","metadata":{}},{"cell_type":"code","source":"def display_confusion_matrix(cmat, score, precision, recall):\n    plt.figure(figsize=(25,25))\n    ax = plt.gca()\n    ax.matshow(cmat, cmap='Reds')\n    ax.set_xticks(range(len(CLASSES)))\n    ax.set_xticklabels(CLASSES, fontdict={'fontsize': 7})\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"left\", rotation_mode=\"anchor\")\n    ax.set_yticks(range(len(CLASSES)))\n    ax.set_yticklabels(CLASSES, fontdict={'fontsize': 7})\n    plt.setp(ax.get_yticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n    titlestring = \"\"\n    if score is not None:\n        titlestring += 'f1 = {:.3f} '.format(score)\n    if precision is not None:\n        titlestring += '\\nprecision = {:.3f} '.format(precision)\n    if recall is not None:\n        titlestring += '\\nrecall = {:.3f} '.format(recall)\n    if len(titlestring) > 0:\n        ax.text(101, 1, titlestring, fontdict={'fontsize': 18, 'horizontalalignment':'right', 'verticalalignment':'top', 'color':'#804040'})\n    \n    if not using_ensemble_models:\n        print('Epoch with min loss and max accuracy:', np.argmin(history.history['val_loss']), np.argmax(history.history['val_sparse_categorical_accuracy']))\n        print('min loss and max accuracy:', round(min(history.history['val_loss']),2), round(max(history.history['val_sparse_categorical_accuracy']),2))\n\n    print(titlestring.replace('\\n', ''))\n    plt.show()\n    \ndef display_training_curves(training, validation, title, subplot):\n    if subplot%10==1: \n        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n        plt.tight_layout()\n    ax = plt.subplot(subplot)\n    ax.set_facecolor('#F8F8F8')\n    ax.plot(training)\n    ax.plot(validation)\n    ax.set_title('model '+ title)\n    ax.set_ylabel(title)\n    #ax.set_ylim(0.28,1.05)\n    ax.set_xlabel('epoch')\n    ax.legend(['train', 'valid.'])","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-01-01T09:03:06.053761Z","iopub.execute_input":"2022-01-01T09:03:06.054690Z","iopub.status.idle":"2022-01-01T09:03:06.071469Z","shell.execute_reply.started":"2022-01-01T09:03:06.054638Z","shell.execute_reply":"2022-01-01T09:03:06.070488Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\ncmdataset = get_validation_dataset(ordered=True)\nimages_ds = cmdataset.map(lambda image, label: image)\nlabels_ds = cmdataset.map(lambda image, label: label).unbatch()\n\ncm_correct_labels = next(iter(labels_ds.batch(num_validation_images))).numpy()\n\nif using_ensemble_models:\n    print('using_ensemble_models')\n    probabilities1 = model_EB7.predict(images_ds)\n    probabilities2 = model_D201.predict(images_ds)\n    cm_probabilities = best_alpha * probabilities1 + (1 - best_alpha) * probabilities2\nelse:\n    cm_probabilities = model.predict(images_ds)\n    \ncm_predictions = np.argmax(cm_probabilities, axis=-1)\n\nlabels = range(len(CLASSES))\ncmat = confusion_matrix(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n)\ncmat = (cmat.T / cmat.sum(axis=1)).T","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:03:06.073751Z","iopub.execute_input":"2022-01-01T09:03:06.074133Z","iopub.status.idle":"2022-01-01T09:03:30.044073Z","shell.execute_reply.started":"2022-01-01T09:03:06.074085Z","shell.execute_reply":"2022-01-01T09:03:30.043221Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"cmat","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:03:30.045529Z","iopub.execute_input":"2022-01-01T09:03:30.045751Z","iopub.status.idle":"2022-01-01T09:03:30.053199Z","shell.execute_reply.started":"2022-01-01T09:03:30.045726Z","shell.execute_reply":"2022-01-01T09:03:30.052057Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"score = f1_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\n\nprecision = precision_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\n\nrecall = recall_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\n\ndisplay_confusion_matrix(cmat, score, precision, recall)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:03:30.055074Z","iopub.execute_input":"2022-01-01T09:03:30.055480Z","iopub.status.idle":"2022-01-01T09:03:35.402012Z","shell.execute_reply.started":"2022-01-01T09:03:30.055439Z","shell.execute_reply":"2022-01-01T09:03:35.400918Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"# 視覺化驗證","metadata":{}},{"cell_type":"code","source":"dataset = get_validation_dataset()\ndataset = dataset.unbatch().batch(20)\nbatch = iter(dataset)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:03:35.403167Z","iopub.execute_input":"2022-01-01T09:03:35.403421Z","iopub.status.idle":"2022-01-01T09:03:35.445819Z","shell.execute_reply.started":"2022-01-01T09:03:35.403394Z","shell.execute_reply":"2022-01-01T09:03:35.444803Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"images, labels = next(batch)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:03:35.447219Z","iopub.execute_input":"2022-01-01T09:03:35.447596Z","iopub.status.idle":"2022-01-01T09:03:36.014543Z","shell.execute_reply.started":"2022-01-01T09:03:35.447553Z","shell.execute_reply":"2022-01-01T09:03:36.013626Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"if using_ensemble_models:\n    probabilities1 = model_EB7.predict(images)\n    probabilities2 = model_D201.predict(images)\n    probabilities = best_alpha * probabilities1 + (1 - best_alpha) * probabilities2\nelse:\n    probabilities = model.predict(images)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:03:36.016096Z","iopub.execute_input":"2022-01-01T09:03:36.016339Z","iopub.status.idle":"2022-01-01T09:03:46.589764Z","shell.execute_reply.started":"2022-01-01T09:03:36.016311Z","shell.execute_reply":"2022-01-01T09:03:46.588803Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"predictions = np.argmax(probabilities, axis=-1)\ndisplay_batch_of_images((images, labels), predictions)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:03:46.590999Z","iopub.execute_input":"2022-01-01T09:03:46.591270Z","iopub.status.idle":"2022-01-01T09:03:49.281498Z","shell.execute_reply.started":"2022-01-01T09:03:46.591239Z","shell.execute_reply":"2022-01-01T09:03:49.280483Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"## 檢查 validation set 上的錯誤","metadata":{}},{"cell_type":"code","source":"mismatches = sum(cm_predictions!=cm_correct_labels)\nprint('validation data上的錯誤: {} / {} ({:.2%})'.format(mismatches, num_validation_images, mismatches/num_validation_images))","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:03:49.282779Z","iopub.execute_input":"2022-01-01T09:03:49.283057Z","iopub.status.idle":"2022-01-01T09:03:49.303598Z","shell.execute_reply.started":"2022-01-01T09:03:49.283027Z","shell.execute_reply":"2022-01-01T09:03:49.302495Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"cmdataset = get_validation_dataset(ordered=True)\nimages_ds = cmdataset.map(lambda image, label: image)\nlabels_ds = cmdataset.map(lambda image, label: label).unbatch()\ncm_correct_labels = next(iter(labels_ds.batch(num_validation_images))).numpy() # get everything as one batch\n\nmismatches_images, mismatches_predictions, mismatches_labels = [], [], []\nmismatches_dataset = tf.data.Dataset.from_tensors([])\nval_batch = iter(cmdataset.unbatch().batch(1))\n\nfor image_index in range(num_validation_images):\n    batch = next(val_batch)\n    if cm_predictions[image_index] != cm_correct_labels[image_index]:\n        print('Predicted vs Correct labels: {}, {}'.format(cm_predictions[image_index], cm_correct_labels[image_index]))\n        #display_batch_of_images(batch, np.array([cm_predictions[image_index]]))\n        #mismatches_dataset = tf.data.Dataset.from_tensors(batch)\n        #mismatches_images.append(tf.data.Dataset.from_tensors(batch))\n        #mismatches_predictions.append(cm_predictions[image_index])\n        #mismatches_labels.append(cm_correct_labels[image_index])","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:03:49.305253Z","iopub.execute_input":"2022-01-01T09:03:49.305573Z","iopub.status.idle":"2022-01-01T09:04:06.540453Z","shell.execute_reply.started":"2022-01-01T09:03:49.305531Z","shell.execute_reply":"2022-01-01T09:04:06.539500Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"dataset = get_validation_dataset()\ndataset = dataset.unbatch().batch(20)\nbatch = iter(dataset)\nimages, labels = next(batch)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:04:06.541629Z","iopub.execute_input":"2022-01-01T09:04:06.541942Z","iopub.status.idle":"2022-01-01T09:04:07.136081Z","shell.execute_reply.started":"2022-01-01T09:04:06.541906Z","shell.execute_reply":"2022-01-01T09:04:07.135068Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"for i in range(3):\n    display_batch_of_images((images, labels), predictions, display_mismatches_only=True)\n    images, labels = next(batch)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:04:07.137337Z","iopub.execute_input":"2022-01-01T09:04:07.137623Z","iopub.status.idle":"2022-01-01T09:04:13.508316Z","shell.execute_reply.started":"2022-01-01T09:04:07.137594Z","shell.execute_reply":"2022-01-01T09:04:13.507425Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"one_batch = next(ds_iter)\ndisplay_batch_of_images(one_batch)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:04:13.509922Z","iopub.execute_input":"2022-01-01T09:04:13.510574Z","iopub.status.idle":"2022-01-01T09:04:16.108610Z","shell.execute_reply.started":"2022-01-01T09:04:13.510521Z","shell.execute_reply":"2022-01-01T09:04:16.107581Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"# 預測test set","metadata":{}},{"cell_type":"markdown","source":"## Test Time Augmentation (TTA) ","metadata":{}},{"cell_type":"code","source":"using_tta = False\ntta_iterations = 3","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:04:16.109760Z","iopub.execute_input":"2022-01-01T09:04:16.110498Z","iopub.status.idle":"2022-01-01T09:04:16.114137Z","shell.execute_reply.started":"2022-01-01T09:04:16.110465Z","shell.execute_reply":"2022-01-01T09:04:16.113527Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"if using_tta:\n    def get_test_dataset(ordered=False):\n        dataset = load_dataset(test_filenames, labeled=False, ordered=ordered)\n        dataset = dataset.map(data_augment, num_parallel_calls=AUTO) #tuning4\n        #dataset = dataset.map(data_augment_v2, num_parallel_calls=AUTO)\n        #dataset = dataset.map(data_augment_v3, num_parallel_calls=AUTO)\n        dataset = dataset.batch(batch_size)\n        dataset = dataset.prefetch(AUTO)\n        return dataset","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:04:16.115150Z","iopub.execute_input":"2022-01-01T09:04:16.115763Z","iopub.status.idle":"2022-01-01T09:04:16.126233Z","shell.execute_reply.started":"2022-01-01T09:04:16.115730Z","shell.execute_reply":"2022-01-01T09:04:16.125260Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"def predict_tta(model, tta_iterations):\n    probs  = []\n    for i in range(tta_iterations):\n        print('TTA iteration ', i)\n        test_ds = get_test_dataset(ordered=True) # since we are splitting the dataset and iterating separately on images and ids, order matters.\n        test_images_ds = test_ds.map(lambda image, idnum: image)\n        \n        if using_ensemble_models:\n            print('using_ensemble_models')\n            probabilities1 = model_EB7.predict(test_images_ds)\n            probabilities2 = model_D201.predict(test_images_ds)\n            probabilities = best_alpha * probabilities1 + (1 - best_alpha) * probabilities2\n            probs.append(probabilities)\n        else:\n            probs.append(model.predict(test_images_ds,verbose=0))\n        \n    return probs","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:04:16.127556Z","iopub.execute_input":"2022-01-01T09:04:16.127891Z","iopub.status.idle":"2022-01-01T09:04:16.139277Z","shell.execute_reply.started":"2022-01-01T09:04:16.127854Z","shell.execute_reply":"2022-01-01T09:04:16.138502Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"test_ds = get_test_dataset(ordered=True)\ntest_images_ds = test_ds.map(lambda image, idnum: image)\n\nif using_tta:\n    print('Predictions using TTA...')\n    probabilities = np.mean(predict_tta(model, tta_iterations), axis=0)\nelse:\n    print('Predictions...')\n    probabilities = model.predict(test_images_ds)\npredictions = np.argmax(probabilities, axis=-1)\nprint(predictions)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:04:16.140456Z","iopub.execute_input":"2022-01-01T09:04:16.141094Z","iopub.status.idle":"2022-01-01T09:04:38.908016Z","shell.execute_reply.started":"2022-01-01T09:04:16.141056Z","shell.execute_reply":"2022-01-01T09:04:38.907090Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"print('using_ensemble_models:', using_ensemble_models)\nprint('Generating submission.csv file...')\n\n# Get image ids from test set and convert to unicode\ntest_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\ntest_ids = next(iter(test_ids_ds.batch(num_test_images))).numpy().astype('U')\n\n# Write the submission file\nnp.savetxt(\n    'submission.csv',\n    np.rec.fromarrays([test_ids, predictions]),\n    fmt=['%s', '%d'],\n    delimiter=',',\n    header='id,label',\n    comments='',\n)\n\n# Look at the first few predictions\n!head submission.csv","metadata":{"execution":{"iopub.status.busy":"2022-01-01T09:04:38.909576Z","iopub.execute_input":"2022-01-01T09:04:38.909884Z","iopub.status.idle":"2022-01-01T09:04:42.018163Z","shell.execute_reply.started":"2022-01-01T09:04:38.909844Z","shell.execute_reply":"2022-01-01T09:04:42.017015Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}